{"version":3,"sources":["../../../../../../nodes/vendors/Ollama/actions/text/message.operation.ts"],"sourcesContent":["import type { Tool } from '@langchain/core/tools';\nimport type { IExecuteFunctions, INodeExecutionData, INodeProperties } from 'n8n-workflow';\nimport { updateDisplayOptions } from 'n8n-workflow';\nimport { zodToJsonSchema } from 'zod-to-json-schema';\n\nimport { getConnectedTools } from '@utils/helpers';\n\nimport type { OllamaChatResponse, OllamaMessage, OllamaTool } from '../../helpers';\nimport { apiRequest } from '../../transport';\nimport { modelRLC } from '../descriptions';\n\nconst properties: INodeProperties[] = [\n\tmodelRLC,\n\t{\n\t\tdisplayName: 'Messages',\n\t\tname: 'messages',\n\t\ttype: 'fixedCollection',\n\t\ttypeOptions: {\n\t\t\tsortable: true,\n\t\t\tmultipleValues: true,\n\t\t},\n\t\tplaceholder: 'Add Message',\n\t\tdefault: { values: [{ content: '', role: 'user' }] },\n\t\toptions: [\n\t\t\t{\n\t\t\t\tdisplayName: 'Values',\n\t\t\t\tname: 'values',\n\t\t\t\tvalues: [\n\t\t\t\t\t{\n\t\t\t\t\t\tdisplayName: 'Content',\n\t\t\t\t\t\tname: 'content',\n\t\t\t\t\t\ttype: 'string',\n\t\t\t\t\t\tdescription: 'The content of the message to be sent',\n\t\t\t\t\t\tdefault: '',\n\t\t\t\t\t\tplaceholder: 'e.g. Hello, how can you help me?',\n\t\t\t\t\t\ttypeOptions: {\n\t\t\t\t\t\t\trows: 2,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tdisplayName: 'Role',\n\t\t\t\t\t\tname: 'role',\n\t\t\t\t\t\ttype: 'options',\n\t\t\t\t\t\tdescription: 'The role of this message in the conversation',\n\t\t\t\t\t\toptions: [\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tname: 'User',\n\t\t\t\t\t\t\t\tvalue: 'user',\n\t\t\t\t\t\t\t\tdescription: 'Message from the user',\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tname: 'Assistant',\n\t\t\t\t\t\t\t\tvalue: 'assistant',\n\t\t\t\t\t\t\t\tdescription: 'Response from the assistant (for conversation history)',\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t],\n\t\t\t\t\t\tdefault: 'user',\n\t\t\t\t\t},\n\t\t\t\t],\n\t\t\t},\n\t\t],\n\t},\n\t{\n\t\tdisplayName: 'Simplify Output',\n\t\tname: 'simplify',\n\t\ttype: 'boolean',\n\t\tdefault: true,\n\t\tdescription: 'Whether to simplify the response or not',\n\t},\n\t{\n\t\tdisplayName: 'Options',\n\t\tname: 'options',\n\t\tplaceholder: 'Add Option',\n\t\ttype: 'collection',\n\t\tdefault: {},\n\t\toptions: [\n\t\t\t{\n\t\t\t\tdisplayName: 'System Message',\n\t\t\t\tname: 'system',\n\t\t\t\ttype: 'string',\n\t\t\t\tdefault: '',\n\t\t\t\tplaceholder: 'e.g. You are a helpful assistant.',\n\t\t\t\tdescription: 'System message to set the context for the conversation',\n\t\t\t\ttypeOptions: {\n\t\t\t\t\trows: 2,\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Temperature',\n\t\t\t\tname: 'temperature',\n\t\t\t\ttype: 'number',\n\t\t\t\tdefault: 0.8,\n\t\t\t\ttypeOptions: {\n\t\t\t\t\tminValue: 0,\n\t\t\t\t\tmaxValue: 2,\n\t\t\t\t\tnumberPrecision: 2,\n\t\t\t\t},\n\t\t\t\tdescription: 'Controls randomness in responses. Lower values make output more focused.',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Output Randomness (Top P)',\n\t\t\t\tname: 'top_p',\n\t\t\t\tdefault: 0.7,\n\t\t\t\tdescription: 'The maximum cumulative probability of tokens to consider when sampling',\n\t\t\t\ttype: 'number',\n\t\t\t\ttypeOptions: {\n\t\t\t\t\tminValue: 0,\n\t\t\t\t\tmaxValue: 1,\n\t\t\t\t\tnumberPrecision: 1,\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Top K',\n\t\t\t\tname: 'top_k',\n\t\t\t\ttype: 'number',\n\t\t\t\tdefault: 40,\n\t\t\t\ttypeOptions: {\n\t\t\t\t\tminValue: 1,\n\t\t\t\t},\n\t\t\t\tdescription: 'Controls diversity by limiting the number of top tokens to consider',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Max Tokens',\n\t\t\t\tname: 'num_predict',\n\t\t\t\ttype: 'number',\n\t\t\t\tdefault: 1024,\n\t\t\t\ttypeOptions: {\n\t\t\t\t\tminValue: 1,\n\t\t\t\t\tnumberPrecision: 0,\n\t\t\t\t},\n\t\t\t\tdescription: 'Maximum number of tokens to generate in the completion',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Frequency Penalty',\n\t\t\t\tname: 'frequency_penalty',\n\t\t\t\ttype: 'number',\n\t\t\t\tdefault: 0.0,\n\t\t\t\ttypeOptions: {\n\t\t\t\t\tminValue: 0,\n\t\t\t\t\tnumberPrecision: 2,\n\t\t\t\t},\n\t\t\t\tdescription:\n\t\t\t\t\t'Adjusts the penalty for tokens that have already appeared in the generated text. Higher values discourage repetition.',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Presence Penalty',\n\t\t\t\tname: 'presence_penalty',\n\t\t\t\ttype: 'number',\n\t\t\t\tdefault: 0.0,\n\t\t\t\ttypeOptions: {\n\t\t\t\t\tnumberPrecision: 2,\n\t\t\t\t},\n\t\t\t\tdescription:\n\t\t\t\t\t'Adjusts the penalty for tokens based on their presence in the generated text so far. Positive values penalize tokens that have already appeared, encouraging diversity.',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Repetition Penalty',\n\t\t\t\tname: 'repeat_penalty',\n\t\t\t\ttype: 'number',\n\t\t\t\tdefault: 1.1,\n\t\t\t\ttypeOptions: {\n\t\t\t\t\tminValue: 0,\n\t\t\t\t\tnumberPrecision: 2,\n\t\t\t\t},\n\t\t\t\tdescription:\n\t\t\t\t\t'Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more strongly, while a lower value (e.g., 0.9) will be more lenient.',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Context Length',\n\t\t\t\tname: 'num_ctx',\n\t\t\t\ttype: 'number',\n\t\t\t\tdefault: 4096,\n\t\t\t\ttypeOptions: {\n\t\t\t\t\tminValue: 1,\n\t\t\t\t\tnumberPrecision: 0,\n\t\t\t\t},\n\t\t\t\tdescription: 'Sets the size of the context window used to generate the next token',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Repeat Last N',\n\t\t\t\tname: 'repeat_last_n',\n\t\t\t\ttype: 'number',\n\t\t\t\tdefault: 64,\n\t\t\t\ttypeOptions: {\n\t\t\t\t\tminValue: -1,\n\t\t\t\t\tnumberPrecision: 0,\n\t\t\t\t},\n\t\t\t\tdescription:\n\t\t\t\t\t'Sets how far back for the model to look back to prevent repetition. (0 = disabled, -1 = num_ctx).',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Min P',\n\t\t\t\tname: 'min_p',\n\t\t\t\ttype: 'number',\n\t\t\t\tdefault: 0.0,\n\t\t\t\ttypeOptions: {\n\t\t\t\t\tminValue: 0,\n\t\t\t\t\tmaxValue: 1,\n\t\t\t\t\tnumberPrecision: 3,\n\t\t\t\t},\n\t\t\t\tdescription:\n\t\t\t\t\t'Alternative to the top_p, and aims to ensure a balance of quality and variety. The parameter p represents the minimum probability for a token to be considered, relative to the probability of the most likely token.',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Seed',\n\t\t\t\tname: 'seed',\n\t\t\t\ttype: 'number',\n\t\t\t\tdefault: 0,\n\t\t\t\ttypeOptions: {\n\t\t\t\t\tminValue: 0,\n\t\t\t\t\tnumberPrecision: 0,\n\t\t\t\t},\n\t\t\t\tdescription:\n\t\t\t\t\t'Sets the random number seed to use for generation. Setting this to a specific number will make the model generate the same text for the same prompt.',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Stop Sequences',\n\t\t\t\tname: 'stop',\n\t\t\t\ttype: 'string',\n\t\t\t\tdefault: '',\n\t\t\t\tdescription:\n\t\t\t\t\t'Sets the stop sequences to use. When this pattern is encountered the LLM will stop generating text and return. Separate multiple patterns with commas',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Keep Alive',\n\t\t\t\tname: 'keep_alive',\n\t\t\t\ttype: 'string',\n\t\t\t\tdefault: '5m',\n\t\t\t\tdescription:\n\t\t\t\t\t'Specifies the duration to keep the loaded model in memory after use. Format: 1h30m (1 hour 30 minutes).',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Low VRAM Mode',\n\t\t\t\tname: 'low_vram',\n\t\t\t\ttype: 'boolean',\n\t\t\t\tdefault: false,\n\t\t\t\tdescription:\n\t\t\t\t\t'Whether to activate low VRAM mode, which reduces memory usage at the cost of slower generation speed. Useful for GPUs with limited memory.',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Main GPU ID',\n\t\t\t\tname: 'main_gpu',\n\t\t\t\ttype: 'number',\n\t\t\t\tdefault: 0,\n\t\t\t\ttypeOptions: {\n\t\t\t\t\tminValue: 0,\n\t\t\t\t\tnumberPrecision: 0,\n\t\t\t\t},\n\t\t\t\tdescription:\n\t\t\t\t\t'Specifies the ID of the GPU to use for the main computation. Only change this if you have multiple GPUs.',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Context Batch Size',\n\t\t\t\tname: 'num_batch',\n\t\t\t\ttype: 'number',\n\t\t\t\tdefault: 512,\n\t\t\t\ttypeOptions: {\n\t\t\t\t\tminValue: 1,\n\t\t\t\t\tnumberPrecision: 0,\n\t\t\t\t},\n\t\t\t\tdescription:\n\t\t\t\t\t'Sets the batch size for prompt processing. Larger batch sizes may improve generation speed but increase memory usage.',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Number of GPUs',\n\t\t\t\tname: 'num_gpu',\n\t\t\t\ttype: 'number',\n\t\t\t\tdefault: -1,\n\t\t\t\ttypeOptions: {\n\t\t\t\t\tminValue: -1,\n\t\t\t\t\tnumberPrecision: 0,\n\t\t\t\t},\n\t\t\t\tdescription:\n\t\t\t\t\t'Specifies the number of GPUs to use for parallel processing. Set to -1 for auto-detection.',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Number of CPU Threads',\n\t\t\t\tname: 'num_thread',\n\t\t\t\ttype: 'number',\n\t\t\t\tdefault: 0,\n\t\t\t\ttypeOptions: {\n\t\t\t\t\tminValue: 0,\n\t\t\t\t\tnumberPrecision: 0,\n\t\t\t\t},\n\t\t\t\tdescription:\n\t\t\t\t\t'Specifies the number of CPU threads to use for processing. Set to 0 for auto-detection.',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Penalize Newlines',\n\t\t\t\tname: 'penalize_newline',\n\t\t\t\ttype: 'boolean',\n\t\t\t\tdefault: true,\n\t\t\t\tdescription:\n\t\t\t\t\t'Whether the model will be less likely to generate newline characters, encouraging longer continuous sequences of text',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Use Memory Locking',\n\t\t\t\tname: 'use_mlock',\n\t\t\t\ttype: 'boolean',\n\t\t\t\tdefault: false,\n\t\t\t\tdescription:\n\t\t\t\t\t'Whether to lock the model in memory to prevent swapping. This can improve performance but requires sufficient available memory.',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Use Memory Mapping',\n\t\t\t\tname: 'use_mmap',\n\t\t\t\ttype: 'boolean',\n\t\t\t\tdefault: true,\n\t\t\t\tdescription:\n\t\t\t\t\t'Whether to use memory mapping for loading the model. This can reduce memory usage but may impact performance.',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Load Vocabulary Only',\n\t\t\t\tname: 'vocab_only',\n\t\t\t\ttype: 'boolean',\n\t\t\t\tdefault: false,\n\t\t\t\tdescription:\n\t\t\t\t\t'Whether to only load the model vocabulary without the weights. Useful for quickly testing tokenization.',\n\t\t\t},\n\t\t\t{\n\t\t\t\tdisplayName: 'Output Format',\n\t\t\t\tname: 'format',\n\t\t\t\ttype: 'options',\n\t\t\t\toptions: [\n\t\t\t\t\t{ name: 'Default', value: '' },\n\t\t\t\t\t{ name: 'JSON', value: 'json' },\n\t\t\t\t],\n\t\t\t\tdefault: '',\n\t\t\t\tdescription: 'Specifies the format of the API response',\n\t\t\t},\n\t\t],\n\t},\n];\n\ninterface MessageOptions {\n\tsystem?: string;\n\ttemperature?: number;\n\ttop_p?: number;\n\ttop_k?: number;\n\tnum_predict?: number;\n\tfrequency_penalty?: number;\n\tpresence_penalty?: number;\n\trepeat_penalty?: number;\n\tnum_ctx?: number;\n\trepeat_last_n?: number;\n\tmin_p?: number;\n\tseed?: number;\n\tstop?: string | string[];\n\tlow_vram?: boolean;\n\tmain_gpu?: number;\n\tnum_batch?: number;\n\tnum_gpu?: number;\n\tnum_thread?: number;\n\tpenalize_newline?: boolean;\n\tuse_mlock?: boolean;\n\tuse_mmap?: boolean;\n\tvocab_only?: boolean;\n\tformat?: string;\n\tkeep_alive?: string;\n}\n\nconst displayOptions = {\n\tshow: {\n\t\toperation: ['message'],\n\t\tresource: ['text'],\n\t},\n};\n\nexport const description = updateDisplayOptions(displayOptions, properties);\n\nexport async function execute(this: IExecuteFunctions, i: number): Promise<INodeExecutionData[]> {\n\tconst model = this.getNodeParameter('modelId', i, '', { extractValue: true }) as string;\n\tconst messages = this.getNodeParameter('messages.values', i, []) as OllamaMessage[];\n\tconst simplify = this.getNodeParameter('simplify', i, true) as boolean;\n\tconst options = this.getNodeParameter('options', i, {}) as MessageOptions;\n\tconst { tools, connectedTools } = await getTools.call(this);\n\n\tif (options.system) {\n\t\tmessages.unshift({\n\t\t\trole: 'system',\n\t\t\tcontent: options.system,\n\t\t});\n\t}\n\n\tdelete options.system;\n\n\tconst processedOptions = { ...options };\n\tif (processedOptions.stop && typeof processedOptions.stop === 'string') {\n\t\tprocessedOptions.stop = processedOptions.stop\n\t\t\t.split(',')\n\t\t\t.map((s: string) => s.trim())\n\t\t\t.filter(Boolean);\n\t}\n\n\tconst body = {\n\t\tmodel,\n\t\tmessages,\n\t\tstream: false,\n\t\ttools,\n\t\toptions: processedOptions,\n\t};\n\n\tlet response: OllamaChatResponse = await apiRequest.call(this, 'POST', '/api/chat', {\n\t\tbody,\n\t});\n\n\tif (tools.length > 0 && response.message.tool_calls && response.message.tool_calls.length > 0) {\n\t\tconst toolCalls = response.message.tool_calls;\n\n\t\tmessages.push(response.message);\n\n\t\tfor (const toolCall of toolCalls) {\n\t\t\tlet toolResponse = '';\n\t\t\tlet toolFound = false;\n\n\t\t\tfor (const tool of connectedTools) {\n\t\t\t\tif (tool.name === toolCall.function.name) {\n\t\t\t\t\ttoolFound = true;\n\t\t\t\t\ttry {\n\t\t\t\t\t\tconst result: unknown = await tool.invoke(toolCall.function.arguments);\n\t\t\t\t\t\ttoolResponse =\n\t\t\t\t\t\t\ttypeof result === 'object' && result !== null\n\t\t\t\t\t\t\t\t? JSON.stringify(result)\n\t\t\t\t\t\t\t\t: String(result);\n\t\t\t\t\t} catch (error) {\n\t\t\t\t\t\ttoolResponse = `Error executing tool: ${error instanceof Error ? error.message : 'Unknown error'}`;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Add tool response even if tool wasn't found to prevent silent failure\n\t\t\tif (!toolFound) {\n\t\t\t\ttoolResponse = `Error: Tool '${toolCall.function.name}' not found`;\n\t\t\t}\n\n\t\t\tmessages.push({\n\t\t\t\trole: 'tool',\n\t\t\t\tcontent: toolResponse,\n\t\t\t\ttool_name: toolCall.function.name,\n\t\t\t});\n\t\t}\n\n\t\tconst updatedBody = {\n\t\t\t...body,\n\t\t\tmessages,\n\t\t};\n\n\t\tresponse = await apiRequest.call(this, 'POST', '/api/chat', {\n\t\t\tbody: updatedBody,\n\t\t});\n\t}\n\n\tif (simplify) {\n\t\treturn [\n\t\t\t{\n\t\t\t\tjson: { content: response.message.content },\n\t\t\t\tpairedItem: { item: i },\n\t\t\t},\n\t\t];\n\t}\n\n\treturn [\n\t\t{\n\t\t\tjson: { ...response },\n\t\t\tpairedItem: { item: i },\n\t\t},\n\t];\n}\n\nasync function getTools(this: IExecuteFunctions) {\n\tlet connectedTools: Tool[] = [];\n\tconst nodeInputs = this.getNodeInputs();\n\n\tif (nodeInputs.some((input) => input.type === 'ai_tool')) {\n\t\tconnectedTools = await getConnectedTools(this, true);\n\t}\n\n\tconst tools: OllamaTool[] = connectedTools.map((tool) => ({\n\t\ttype: 'function',\n\t\tfunction: {\n\t\t\tname: tool.name,\n\t\t\tdescription: tool.description,\n\t\t\tparameters: zodToJsonSchema(tool.schema),\n\t\t},\n\t}));\n\n\treturn { tools, connectedTools };\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA,0BAAqC;AACrC,gCAAgC;AAEhC,qBAAkC;AAGlC,uBAA2B;AAC3B,0BAAyB;AAEzB,MAAM,aAAgC;AAAA,EACrC;AAAA,EACA;AAAA,IACC,aAAa;AAAA,IACb,MAAM;AAAA,IACN,MAAM;AAAA,IACN,aAAa;AAAA,MACZ,UAAU;AAAA,MACV,gBAAgB;AAAA,IACjB;AAAA,IACA,aAAa;AAAA,IACb,SAAS,EAAE,QAAQ,CAAC,EAAE,SAAS,IAAI,MAAM,OAAO,CAAC,EAAE;AAAA,IACnD,SAAS;AAAA,MACR;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,QAAQ;AAAA,UACP;AAAA,YACC,aAAa;AAAA,YACb,MAAM;AAAA,YACN,MAAM;AAAA,YACN,aAAa;AAAA,YACb,SAAS;AAAA,YACT,aAAa;AAAA,YACb,aAAa;AAAA,cACZ,MAAM;AAAA,YACP;AAAA,UACD;AAAA,UACA;AAAA,YACC,aAAa;AAAA,YACb,MAAM;AAAA,YACN,MAAM;AAAA,YACN,aAAa;AAAA,YACb,SAAS;AAAA,cACR;AAAA,gBACC,MAAM;AAAA,gBACN,OAAO;AAAA,gBACP,aAAa;AAAA,cACd;AAAA,cACA;AAAA,gBACC,MAAM;AAAA,gBACN,OAAO;AAAA,gBACP,aAAa;AAAA,cACd;AAAA,YACD;AAAA,YACA,SAAS;AAAA,UACV;AAAA,QACD;AAAA,MACD;AAAA,IACD;AAAA,EACD;AAAA,EACA;AAAA,IACC,aAAa;AAAA,IACb,MAAM;AAAA,IACN,MAAM;AAAA,IACN,SAAS;AAAA,IACT,aAAa;AAAA,EACd;AAAA,EACA;AAAA,IACC,aAAa;AAAA,IACb,MAAM;AAAA,IACN,aAAa;AAAA,IACb,MAAM;AAAA,IACN,SAAS,CAAC;AAAA,IACV,SAAS;AAAA,MACR;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa;AAAA,QACb,aAAa;AAAA,QACb,aAAa;AAAA,UACZ,MAAM;AAAA,QACP;AAAA,MACD;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa;AAAA,UACZ,UAAU;AAAA,UACV,UAAU;AAAA,UACV,iBAAiB;AAAA,QAClB;AAAA,QACA,aAAa;AAAA,MACd;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa;AAAA,QACb,MAAM;AAAA,QACN,aAAa;AAAA,UACZ,UAAU;AAAA,UACV,UAAU;AAAA,UACV,iBAAiB;AAAA,QAClB;AAAA,MACD;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa;AAAA,UACZ,UAAU;AAAA,QACX;AAAA,QACA,aAAa;AAAA,MACd;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa;AAAA,UACZ,UAAU;AAAA,UACV,iBAAiB;AAAA,QAClB;AAAA,QACA,aAAa;AAAA,MACd;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa;AAAA,UACZ,UAAU;AAAA,UACV,iBAAiB;AAAA,QAClB;AAAA,QACA,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa;AAAA,UACZ,iBAAiB;AAAA,QAClB;AAAA,QACA,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa;AAAA,UACZ,UAAU;AAAA,UACV,iBAAiB;AAAA,QAClB;AAAA,QACA,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa;AAAA,UACZ,UAAU;AAAA,UACV,iBAAiB;AAAA,QAClB;AAAA,QACA,aAAa;AAAA,MACd;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa;AAAA,UACZ,UAAU;AAAA,UACV,iBAAiB;AAAA,QAClB;AAAA,QACA,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa;AAAA,UACZ,UAAU;AAAA,UACV,UAAU;AAAA,UACV,iBAAiB;AAAA,QAClB;AAAA,QACA,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa;AAAA,UACZ,UAAU;AAAA,UACV,iBAAiB;AAAA,QAClB;AAAA,QACA,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa;AAAA,UACZ,UAAU;AAAA,UACV,iBAAiB;AAAA,QAClB;AAAA,QACA,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa;AAAA,UACZ,UAAU;AAAA,UACV,iBAAiB;AAAA,QAClB;AAAA,QACA,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa;AAAA,UACZ,UAAU;AAAA,UACV,iBAAiB;AAAA,QAClB;AAAA,QACA,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aAAa;AAAA,UACZ,UAAU;AAAA,UACV,iBAAiB;AAAA,QAClB;AAAA,QACA,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,aACC;AAAA,MACF;AAAA,MACA;AAAA,QACC,aAAa;AAAA,QACb,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,UACR,EAAE,MAAM,WAAW,OAAO,GAAG;AAAA,UAC7B,EAAE,MAAM,QAAQ,OAAO,OAAO;AAAA,QAC/B;AAAA,QACA,SAAS;AAAA,QACT,aAAa;AAAA,MACd;AAAA,IACD;AAAA,EACD;AACD;AA6BA,MAAM,iBAAiB;AAAA,EACtB,MAAM;AAAA,IACL,WAAW,CAAC,SAAS;AAAA,IACrB,UAAU,CAAC,MAAM;AAAA,EAClB;AACD;AAEO,MAAM,kBAAc,0CAAqB,gBAAgB,UAAU;AAE1E,eAAsB,QAAiC,GAA0C;AAChG,QAAM,QAAQ,KAAK,iBAAiB,WAAW,GAAG,IAAI,EAAE,cAAc,KAAK,CAAC;AAC5E,QAAM,WAAW,KAAK,iBAAiB,mBAAmB,GAAG,CAAC,CAAC;AAC/D,QAAM,WAAW,KAAK,iBAAiB,YAAY,GAAG,IAAI;AAC1D,QAAM,UAAU,KAAK,iBAAiB,WAAW,GAAG,CAAC,CAAC;AACtD,QAAM,EAAE,OAAO,eAAe,IAAI,MAAM,SAAS,KAAK,IAAI;AAE1D,MAAI,QAAQ,QAAQ;AACnB,aAAS,QAAQ;AAAA,MAChB,MAAM;AAAA,MACN,SAAS,QAAQ;AAAA,IAClB,CAAC;AAAA,EACF;AAEA,SAAO,QAAQ;AAEf,QAAM,mBAAmB,EAAE,GAAG,QAAQ;AACtC,MAAI,iBAAiB,QAAQ,OAAO,iBAAiB,SAAS,UAAU;AACvE,qBAAiB,OAAO,iBAAiB,KACvC,MAAM,GAAG,EACT,IAAI,CAAC,MAAc,EAAE,KAAK,CAAC,EAC3B,OAAO,OAAO;AAAA,EACjB;AAEA,QAAM,OAAO;AAAA,IACZ;AAAA,IACA;AAAA,IACA,QAAQ;AAAA,IACR;AAAA,IACA,SAAS;AAAA,EACV;AAEA,MAAI,WAA+B,MAAM,4BAAW,KAAK,MAAM,QAAQ,aAAa;AAAA,IACnF;AAAA,EACD,CAAC;AAED,MAAI,MAAM,SAAS,KAAK,SAAS,QAAQ,cAAc,SAAS,QAAQ,WAAW,SAAS,GAAG;AAC9F,UAAM,YAAY,SAAS,QAAQ;AAEnC,aAAS,KAAK,SAAS,OAAO;AAE9B,eAAW,YAAY,WAAW;AACjC,UAAI,eAAe;AACnB,UAAI,YAAY;AAEhB,iBAAW,QAAQ,gBAAgB;AAClC,YAAI,KAAK,SAAS,SAAS,SAAS,MAAM;AACzC,sBAAY;AACZ,cAAI;AACH,kBAAM,SAAkB,MAAM,KAAK,OAAO,SAAS,SAAS,SAAS;AACrE,2BACC,OAAO,WAAW,YAAY,WAAW,OACtC,KAAK,UAAU,MAAM,IACrB,OAAO,MAAM;AAAA,UAClB,SAAS,OAAO;AACf,2BAAe,yBAAyB,iBAAiB,QAAQ,MAAM,UAAU,eAAe;AAAA,UACjG;AACA;AAAA,QACD;AAAA,MACD;AAGA,UAAI,CAAC,WAAW;AACf,uBAAe,gBAAgB,SAAS,SAAS,IAAI;AAAA,MACtD;AAEA,eAAS,KAAK;AAAA,QACb,MAAM;AAAA,QACN,SAAS;AAAA,QACT,WAAW,SAAS,SAAS;AAAA,MAC9B,CAAC;AAAA,IACF;AAEA,UAAM,cAAc;AAAA,MACnB,GAAG;AAAA,MACH;AAAA,IACD;AAEA,eAAW,MAAM,4BAAW,KAAK,MAAM,QAAQ,aAAa;AAAA,MAC3D,MAAM;AAAA,IACP,CAAC;AAAA,EACF;AAEA,MAAI,UAAU;AACb,WAAO;AAAA,MACN;AAAA,QACC,MAAM,EAAE,SAAS,SAAS,QAAQ,QAAQ;AAAA,QAC1C,YAAY,EAAE,MAAM,EAAE;AAAA,MACvB;AAAA,IACD;AAAA,EACD;AAEA,SAAO;AAAA,IACN;AAAA,MACC,MAAM,EAAE,GAAG,SAAS;AAAA,MACpB,YAAY,EAAE,MAAM,EAAE;AAAA,IACvB;AAAA,EACD;AACD;AAEA,eAAe,WAAkC;AAChD,MAAI,iBAAyB,CAAC;AAC9B,QAAM,aAAa,KAAK,cAAc;AAEtC,MAAI,WAAW,KAAK,CAAC,UAAU,MAAM,SAAS,SAAS,GAAG;AACzD,qBAAiB,UAAM,kCAAkB,MAAM,IAAI;AAAA,EACpD;AAEA,QAAM,QAAsB,eAAe,IAAI,CAAC,UAAU;AAAA,IACzD,MAAM;AAAA,IACN,UAAU;AAAA,MACT,MAAM,KAAK;AAAA,MACX,aAAa,KAAK;AAAA,MAClB,gBAAY,2CAAgB,KAAK,MAAM;AAAA,IACxC;AAAA,EACD,EAAE;AAEF,SAAO,EAAE,OAAO,eAAe;AAChC;","names":[]}